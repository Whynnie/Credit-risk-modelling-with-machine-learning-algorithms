{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d0a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING NECCESSARY LIBRARIES \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "\n",
    "# IMPORTING THE DATASET\n",
    "df_loan = pd.read_csv('german_credit_data.csv', index_col=0)\n",
    "df_loan.head()\n",
    "\n",
    "\n",
    "\n",
    "# Exploratory data analysis (EDA)\n",
    "\n",
    "# Age\n",
    "sns.displot(df_loan[\"Age\"], kde = True)\n",
    "plt.xlabel('Age', fontsize = 15)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "df_loan[df_loan['Risk']== \"bad\"]['Age'].hist(alpha=0.9,color='red',\n",
    "                                              bins=30,label='Bad Risk')\n",
    "df_loan[df_loan['Risk']== \"good\"]['Age'].hist(alpha=0.6,color='blue',\n",
    "                                              bins=30,label='Good Risk')\n",
    "plt.legend()\n",
    "plt.xlabel('Age', fontsize = 15)\n",
    "\n",
    "sns.boxplot(y= \"Age\", x = \"Risk\", data = df_loan)\n",
    "plt.xlabel('Age', fontsize = 15)\n",
    "\n",
    "# Credit Amount\n",
    "sns.displot(df_loan[\"Credit amount\"])\n",
    "plt.xlabel('Credit amount', fontsize = 15)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "df_loan[df_loan['Risk']== \"bad\"]['Credit amount'].hist(alpha=0.9,color='red',\n",
    "                                              bins=30,label='Bad Risk')\n",
    "df_loan[df_loan['Risk']== \"good\"]['Credit amount'].hist(alpha=0.6,color='green',\n",
    "                                              bins=30,label='Good Risk')\n",
    "plt.legend()\n",
    "plt.xlabel('Credit Amount', fontsize = 15)\n",
    "\n",
    "sns.boxplot(y= \"Credit amount\", x = \"Risk\", data = df_loan)\n",
    "plt.xlabel('Credit amount', fontsize = 15)\n",
    "\n",
    "## Duration\n",
    "sns.boxplot(x = \"Risk\", y = \"Duration\", data = df_loan)\n",
    "plt.xlabel('Duration', fontsize = 15)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "df_loan[df_loan['Risk']== \"bad\"]['Duration'].hist(alpha=0.7,color='red',\n",
    "                                              bins=30,label='Bad Risk')\n",
    "df_loan[df_loan['Risk']== \"good\"]['Duration'].hist(alpha=0.6,color='blue',\n",
    "                                              bins=30,label='Good Risk')\n",
    "plt.legend()\n",
    "plt.xlabel('Duration', fontsize = 15)\n",
    "\n",
    "## Risk\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.countplot(\"Risk\", data = df_loan)\n",
    "plt.xlabel('Risk', fontsize = 15)\n",
    "\n",
    "## Sex\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.countplot(\"Sex\", data = df_loan, hue = \"Risk\")\n",
    "plt.xlabel('Sex', fontsize = 15)\n",
    "\n",
    "## Checking accounts\n",
    "plt.figure(figsize= (7, 5))\n",
    "sns.boxplot(\"Checking account\", \"Credit amount\", data = df_loan)\n",
    "plt.xlabel('Checking account', fontsize = 15)\n",
    "\n",
    "plt.figure(figsize= (7, 5))\n",
    "sns.countplot(\"Checking account\", data = df_loan, hue = \"Risk\")\n",
    "plt.xlabel('Checking account', fontsize = 15)\n",
    "\n",
    "sns.countplot(\"Saving accounts\", data = df_loan, hue = \"Risk\")\n",
    "plt.xlabel('Saving accounts', fontsize = 15)\n",
    "\n",
    "## Housing\n",
    "sns.countplot(\"Housing\", data = df_loan, hue = \"Risk\")\n",
    "plt.xlabel('Housing', fontsize = 15)\n",
    "\n",
    "\n",
    "\n",
    "# PRE-PROCESSING\n",
    "\n",
    "## Sex\n",
    "df_loan[\"Sex\"].value_counts()\n",
    "#cross table for the 'Sex' feature\n",
    "cross_sex = pd.crosstab(df_loan['Risk'], df_loan['Sex']).apply(lambda x: x/x.sum() * 100)\n",
    "decimals = pd.Series([2,2], index=['Male', 'Female'])\n",
    "cross_sex = cross_sex.round(2)\n",
    "cross_sex_transposed = cross_sex.T\n",
    "cross_sex_transposed\n",
    "# Performing OneHotEncoding\n",
    "df_loan[\"Sex\"] = df_loan[\"Sex\"].apply(lambda x:1 if x==\"male\" else 0)\n",
    "df_loan[\"Sex\"].head()\n",
    "\n",
    "## job\n",
    "# Where; 0 - unskilled and non-resident, 1 - unskilled and resident, 2 - skilled, 3 - highly skilled\n",
    "df_loan[\"Job\"].head()\n",
    "\n",
    "## Housing\n",
    "df_loan[\"Housing\"].value_counts()\n",
    "#cross table for the 'housing' feature\n",
    "cross_housing = pd.crosstab(df_loan['Risk'], df_loan['Housing']).apply(lambda x: x/x.sum() * 100)\n",
    "cross_housing = cross_housing.round(2)\n",
    "cross_housing_transposed = cross_housing.T\n",
    "cross_housing_transposed\n",
    "## Performing OneHotEncoding\n",
    "# 1- Own, 2- Rent, 0- Free\n",
    "df_loan[\"Housing\"].replace([\"own\", \"rent\", \"free\"], [1, 2, 0], inplace = True)\n",
    "df_loan[\"Housing\"].head()\n",
    "\n",
    "## Purpose\n",
    "df_loan[\"Purpose\"].value_counts(normalize = True)\n",
    "df_loan[\"Purpose\"].replace([\"repairs\", \"radio/TV\", \"vacation/others\"], \"others\", inplace = True)\n",
    "df_loan[\"Purpose\"].replace([\"furniture/equipment\", \"domestic appliances\"], \"domestic equipments\", inplace = True)\n",
    "df_loan[\"Purpose\"].value_counts()\n",
    "#cross table for the 'Purpose' feature\n",
    "cross_sex = pd.crosstab(df_loan['Risk'], df_loan['Purpose']).apply(lambda x: x/x.sum() * 100)\n",
    "cross_sex = cross_sex.round(2)\n",
    "cross_sex_transposed = cross_sex.T\n",
    "cross_sex_transposed\n",
    "## Performing OneHotEncoding\n",
    "# where; 0- others, 1- business, 2- car, 3- domestic equipments, 4- education.\n",
    "df_loan[\"Purpose\"].replace([\"others\", \"business\", \"car\", \"domestic equipments\", \"education\"], [0, 1, 2, 3, 4], inplace = True)\n",
    "df_loan.head()\n",
    "\n",
    "## Saving Accounts\n",
    "df_loan[\"Saving accounts\"].value_counts(normalize= True)\n",
    "df_loan[\"Saving accounts\"].fillna(\"None\", inplace= True)\n",
    "df_loan[\"Saving accounts\"].value_counts(normalize= True)\n",
    "#cross table for the 'Saving accounts' feature\n",
    "cross_sex = pd.crosstab(df_loan['Risk'], df_loan['Saving accounts']).apply(lambda x: x/x.sum() * 100)\n",
    "cross_sex = cross_sex.round(2)\n",
    "cross_sex_transposed = cross_sex.T\n",
    "cross_sex_transposed\n",
    "## Performing OneHotEncoding\n",
    "df_loan[\"Saving accounts\"].replace([\"little\", \"None\", \"moderate\", \"quite rich\", \"rich\"], [1, 0, 2, 4, 3], inplace= True)\n",
    "df_loan[\"Saving accounts\"].head()\n",
    "\n",
    "## Checking Account\n",
    "df_loan[\"Checking account\"].value_counts(normalize= True)\n",
    "df_loan[\"Checking account\"].fillna(\"None\", inplace= True)\n",
    "df_loan[\"Checking account\"].value_counts(normalize= True)\n",
    "#cross table for the 'Checking account' feature\n",
    "cross_sex = pd.crosstab(df_loan['Risk'], df_loan['Checking account']).apply(lambda x: x/x.sum() * 100)\n",
    "cross_sex = cross_sex.round(2)\n",
    "cross_sex_transposed = cross_sex.T\n",
    "cross_sex_transposed\n",
    "## Performing OneHotEncoding\n",
    "df_loan[\"Checking account\"].replace([\"little\", \"None\", \"moderate\", \"rich\"], [1, 0, 2, 3], inplace= True)\n",
    "df_loan[\"Checking account\"].head()\n",
    "df_loan.head()\n",
    "\n",
    "## Preprocessing the dependent variable - Risk\n",
    "df_loan[\"Risk\"].value_counts(normalize= True)\n",
    "## Encoding the dependent variable\n",
    "df_loan[\"Risk_Status\"] = df_loan[\"Risk\"].apply(lambda x:1 if x == \"bad\" else 0)\n",
    "df_loan[\"Risk_Status\"].head()\n",
    "df_loan.head()\n",
    "df_loan.tail()\n",
    "df_loan.drop(\"Risk\", axis = 1, inplace = True)\n",
    "df_loan.head()\n",
    "\n",
    "\n",
    "## Scalling the dataset\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_loan.drop(\"Risk_Status\", axis = 1)) \n",
    "scaled_features = scaler.transform(df_loan.drop(\"Risk_Status\", axis = 1))\n",
    "scaled_features\n",
    "df_feat = pd.DataFrame(scaled_features, columns = df_loan.columns[:-1])\n",
    "df_feat.head()\n",
    "\n",
    "\n",
    "### Train test split\n",
    "X = df_feat\n",
    "y = df_loan[\"Risk_Status\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 101)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# BUILDING THE MODELS\n",
    "\n",
    "\n",
    "# KNN Model\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric = \"euclidean\")\n",
    "knn.fit(X_train, y_train)\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "### Evaluation of the KNN model\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(\"===========================================================\")\n",
    "print(classification_report(y_test, pred))\n",
    "print(f\"Train Accuracy : {knn.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test Accuracy : {knn.score(X_test, y_test):.3f}\")\n",
    "\n",
    "### Exploring the model using Grid search cv\n",
    "knn_gs = KNeighborsClassifier()\n",
    "parameters = {\n",
    "    \"n_neighbors\": [2, 3, 21, 22],\n",
    "    \"metric\": [\"minkowski\", \"euclidean\"],\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"p\": [1,2,3,4,5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = knn_gs, \n",
    "                           param_grid = parameters, \n",
    "                           scoring = \"accuracy\", \n",
    "                           cv = 10)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_\n",
    "accuracy = grid_search.best_score_\n",
    "accuracy\n",
    "knn_model = KNeighborsClassifier(n_neighbors = 21, p = 2, weights = \"uniform\")\n",
    "knn_model.fit(X_train, y_train)\n",
    "print(f\"Train Accuracy : {knn_model.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test Accuracy : {knn_model.score(X_test, y_test):.3f}\")\n",
    "pred = knn_model.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(\"===========================================================\")\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "### Learning curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(test_size =0.2, random_state = 101)\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Accuracy Scores\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.grid()\n",
    "    \n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, \n",
    "                     alpha=0.1,color=\"r\")\n",
    "    \n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, \n",
    "                     alpha=0.1, color=\"g\")\n",
    "    \n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "X, y = X_train, y_train\n",
    "\n",
    "title = \"Learning Curve (Tuned K-Nearest Neighbors)\"\n",
    "cv = ShuffleSplit(test_size=0.2, random_state=0)\n",
    "plot_learning_curve(knn_model, title, X, y, ylim=(0.5, 1.02), cv=cv, n_jobs=4)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# logistic Regreression\n",
    "\n",
    "logmode = LogisticRegression()\n",
    "logmode.fit(X_train, y_train)\n",
    "predictions = logmode.predict(X_test)\n",
    "logmode.intercept_, logmode.coef_\n",
    "\n",
    "#Model Evaluation\n",
    "print(f\"Train Accuracy : {logmode.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test Accuracy : {logmode.score(X_test, y_test):.3f}\")\n",
    "confusion_matrix(y_test, predictions)\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "## Parameter tunning\n",
    "log_gs = LogisticRegression()\n",
    "\n",
    "parameter = {\n",
    "    \"C\": np.logspace(-4, 4, 20), \n",
    "    \"penalty\": [\"l1\", \"l2\", 'elasticnet'], ## L1- Lasso, L2- Ridge\n",
    "    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"], \n",
    "    \"max_iter\": [100, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(log_gs, parameter, scoring = \"accuracy\",\n",
    "                           cv = 10, verbose = True, n_jobs = 1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "accuracy = grid_search.best_score_; accuracy\n",
    "grid_search.best_estimator_\n",
    "\n",
    "log_model = LogisticRegression(C = 0.004832930238571752, solver='liblinear', max_iter = 100)\n",
    "log_model.fit(X_train, y_train)\n",
    "print(f\"Train Accuracy : {log_model.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test Accuracy : {log_model.score(X_test, y_test):.3f}\")\n",
    "pred = log_model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(\"===========================================================\")\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "### Learning Curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Accuracy Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, \n",
    "                     alpha=0.1,color=\"r\")\n",
    "    \n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, \n",
    "                     alpha=0.1, color=\"g\")\n",
    "    \n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "X, y = X_train, y_train\n",
    "title = \"Learning Curves (Logistic Regression))\"\n",
    "cv = ShuffleSplit(test_size=0.2, random_state=0)\n",
    "estimator = LogisticRegression()\n",
    "\n",
    "plot_learning_curve(estimator, title, X, y, ylim=(0.5, 1.02), cv=cv, n_jobs=4)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Naive bayes (NB)\n",
    "\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "pred = naive_bayes.predict(X_test)\n",
    "print(f\"Train Accuracy : {naive_bayes.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test Accuracy : {naive_bayes.score(X_test, y_test):.3f}\")\n",
    "\n",
    "accuracy_score(y_test, pred)\n",
    "confusion_matrix(y_test, pred)\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "# Best Parameter\n",
    "nb_gs = GaussianNB()\n",
    "parameters = {\n",
    "    \"var_smoothing\": np.logspace(0, -9, num = 100), \n",
    "}\n",
    "grid_search = GridSearchCV(estimator = nb_gs, \n",
    "                           param_grid = parameters, \n",
    "                           scoring = \"accuracy\", \n",
    "                           cv = 10, \n",
    "                           n_jobs = -1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "nb_gs.get_params().keys()\n",
    "grid_search.best_params_\n",
    "accuracy = grid_search.best_score_; accuracy\n",
    "grid_search.best_estimator_\n",
    "\n",
    "nb_model = GaussianNB(var_smoothing = 8.111308307896873e-06)\n",
    "nb_model.fit(X_train, y_train)\n",
    "print(f\"Train Accuracy : {nb_model.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test Accuracy : {nb_model.score(X_test, y_test):.3f}\")\n",
    "\n",
    "pred = nb_model.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(\"===========================================================\")\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "### Learning Curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Accuracy Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.grid()\n",
    "    \n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, \n",
    "                     alpha=0.1,color=\"r\")\n",
    "    \n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, \n",
    "                     alpha=0.1, color=\"g\")\n",
    "    \n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "X, y = X_train, y_train\n",
    "\n",
    "title = \"Learning Curves (Naive Bayes))\"\n",
    "cv = ShuffleSplit(test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = GaussianNB()\n",
    "plot_learning_curve(estimator, title, X, y, ylim=(0.5, 1.02), cv=cv, n_jobs=4)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Support vecctor machines\n",
    "\n",
    "svc_classifier = SVC()\n",
    "svc_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc_classifier.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)\n",
    "print(f\"Train Accuracy : {svc_classifier.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test Accuracy : {svc_classifier.score(X_test, y_test):.3f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Best Parameter\n",
    "svm_gs = SVC()\n",
    "parameters = {\n",
    "    'kernel': ['rbf','poly'], \n",
    "    'degree': [1, 2, 3, 4, 5, 6, 7]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator = svm_gs, \n",
    "                           param_grid = parameters, \n",
    "                           scoring = \"accuracy\", \n",
    "                           cv = 5, \n",
    "                           n_jobs = -1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_\n",
    "accuracy = grid_search.best_score_; accuracy\n",
    "grid_search.best_estimator_\n",
    "\n",
    "svm_model = SVC(degree=6, kernel='poly')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Train Accuracy : {svm_model.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test Accuracy : {svm_model.score(X_test, y_test):.3f}\")\n",
    "\n",
    "pred = svm_model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(\"===========================================================\")\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "### Learning Curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Accuracy Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.grid()\n",
    "    \n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, \n",
    "                     alpha=0.1,color=\"r\")\n",
    "    \n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, \n",
    "                     alpha=0.1, color=\"g\")\n",
    "    \n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "X, y = X_train, y_train\n",
    "\n",
    "title = \"Learning Curves (SVM)\"\n",
    "cv = ShuffleSplit(test_size=0.2, random_state=0)\n",
    "estimator = svm_model\n",
    "plot_learning_curve(estimator, title, X, y, ylim=(0.5, 1.02), cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "\n",
    "rfc_classifier = RandomForestClassifier(n_jobs= -1, oob_score= False, random_state= 0)\n",
    "rfc_classifier.fit(X_train, y_train)\n",
    "\n",
    "pred = rfc_classifier.predict(X_test)\n",
    "accuracy_score(y_test, pred)\n",
    "confusion_matrix(y_test, pred)\n",
    "\n",
    "print(f\"Train Accuracy : {rfc_classifier.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test Accuracy : {rfc_classifier.score(X_test, y_test):.3f}\")\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "## Applying GridSearchCV\n",
    "grid = {\n",
    "    'n_estimators': [50, 60, 70, 75, 80, 90], \n",
    "    'max_depth': [5, 7, 8, 9, 10, 12, 15], \n",
    "    'max_features': [2, 3, 4, 5], \n",
    "    'min_samples_leaf' :[1, 2, 3, 4], \n",
    "    'min_samples_split': [2, 4, 5, 6, 7, 8], \n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "grid_search_1 = GridSearchCV(estimator = rfc_classifier, \n",
    "                           param_grid = grid, \n",
    "                           scoring = \"accuracy\", \n",
    "                           verbose = 2,\n",
    "                           cv = 4)\n",
    "\n",
    "grid_search_1 = grid_search_1.fit(X_train, y_train)\n",
    "grid_search_1.best_estimator_\n",
    "accuracy = grid_search_1.best_score_; accuracy\n",
    "grid_search_1.best_params_\n",
    "\n",
    "rfc_classifier = RandomForestClassifier(criterion='entropy', max_depth=12, max_features=5,\n",
    "                       min_samples_leaf=2, min_samples_split=7, n_estimators=80,\n",
    "                       n_jobs=-1, random_state=0)\n",
    "\n",
    "rfc_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "print(f\"Train Accuracy : {rfc_classifier.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test Accuracy : {rfc_classifier.score(X_test, y_test):.3f}\")\n",
    "\n",
    "pred = rfc_classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(\"===========================================================\")\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "### Learning Curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Accuracy Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.grid()\n",
    "    \n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, \n",
    "                     alpha=0.1,color=\"r\")\n",
    "    \n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, \n",
    "                     alpha=0.1, color=\"g\")\n",
    "    \n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "X, y = X_train, y_train\n",
    "\n",
    "title = \"Learning Curves (Random Forest)\"\n",
    "cv = ShuffleSplit(test_size=0.2, random_state=0)\n",
    "estimator = rfc_classifier\n",
    "plot_learning_curve(estimator, title, X, y, ylim=(0.5, 1.02), cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Decision trees\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "pred = dtree.predict(X_test)\n",
    "print(f\"Train Accuracy : {dtree.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test Accuracy : {dtree.score(X_test, y_test):.3f}\")\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(\"===========================================================\")\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "# Best Parameter\n",
    "dtree_gs = DecisionTreeClassifier()\n",
    "\n",
    "parameters = {\n",
    "    'criterion': ['gini','entropy'], \n",
    "    'min_samples_split': [2 ,4 ,6 ,8 ,10 ,15]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = dtree_gs, \n",
    "                           param_grid = parameters, \n",
    "                           scoring = \"accuracy\", \n",
    "                           cv = 5, \n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "grid_search.best_params_\n",
    "accuracy = grid_search.best_score_; accuracy\n",
    "grid_search.best_estimator_\n",
    "\n",
    "dtree_model = DecisionTreeClassifier(min_samples_split=15)\n",
    "dtree_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Train Accuracy : {dtree_model.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test Accuracy : {dtree_model.score(X_test, y_test):.3f}\")\n",
    "\n",
    "pred = dtree_model.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(\"===========================================================\")\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "### Learning Curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Accuracy Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.grid()\n",
    "    \n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, \n",
    "                     alpha=0.1,color=\"r\")\n",
    "    \n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, \n",
    "                     alpha=0.1, color=\"g\")\n",
    "    \n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "X, y = X_train, y_train\n",
    "\n",
    "title = \"Learning Curves (Decision Trees)\"\n",
    "cv = ShuffleSplit(test_size=0.2, random_state=0)\n",
    "estimator = dtree_model\n",
    "plot_learning_curve(estimator, title, X, y, ylim=(0.5, 1.02), cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# BUILDIING THE BEST MODEL \n",
    "\n",
    "rfc_classifier = RandomForestClassifier(criterion='entropy', max_depth=12, max_features=5,\n",
    "                       min_samples_leaf=2, min_samples_split=7, n_estimators=80,\n",
    "                       n_jobs=-1, random_state=0)\n",
    "\n",
    "rfc_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "print(f\"Train Accuracy : {rfc_classifier.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test Accuracy : {rfc_classifier.score(X_test, y_test):.3f}\")\n",
    "\n",
    "# Prediction of Test\n",
    "pred_proba = rfc_classifier.predict_proba(X_test)[:, 1]\n",
    "pred_proba\n",
    "\n",
    "# Feature Importance\n",
    "X_test.columns\n",
    "feat_imp = pd.DataFrame({\"Variable\": X_test.columns, \n",
    "                         \"Importance\": rfc_classifier.feature_importances_}).sort_values(\n",
    "    by = \"Importance\", ascending= False).reset_index(drop = True)\n",
    "feat_imp\n",
    "feat_imp.sort_values(\"Importance\").plot(\"Variable\", \"Importance\", \"barh\", figsize = (10, 5))\n",
    "\n",
    "\n",
    "# DECISION MAKING\n",
    "\n",
    "### ROC curve\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='blue', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pred_proba, )\n",
    "print(tpr)\n",
    "print(fpr)\n",
    "print(thresholds)\n",
    "\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, pred_proba):.3f}\")\n",
    "\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(f\"Threshold value is: {optimal_threshold:.3f}\")\n",
    "\n",
    "plot_roc_curve(fpr, tpr)\n",
    "\n",
    "#### acceptance rate;\n",
    "df_accept = pd.DataFrame({\"Actual Test\": y_test, \"Probability of default\": pred_proba})\n",
    "df_accept\n",
    "\n",
    "df_accept['Prediction'] = np.where(df_accept['Probability of default'] > optimal_threshold, 1, 0)\n",
    "df_accept\n",
    "\n",
    "df_accept[\"accept or reject\"] = np.where(df_accept[\"Prediction\"] == 1, \"reject\", \"accept\")\n",
    "df_accept = df_accept.reset_index(drop = True)\n",
    "df_accept.head()\n",
    "df_accept.tail()\n",
    "\n",
    "pd.crosstab(df_accept['Actual Test'], df_accept['Prediction'], rownames = ['Actual'], colnames = ['Predicted'])\n",
    "pd.crosstab(df_accept['Actual Test'], df_accept['Prediction'], rownames = ['Actual'], colnames = ['Predicted']) / df_accept.shape[0]\n",
    "\n",
    "actual = df_accept[\"Actual Test\"]\n",
    "thresh_pred = df_accept[\"Prediction\"]\n",
    "\n",
    "print(classification_report(actual, thresh_pred))\n",
    "print(confusion_matrix(actual, thresh_pred))\n",
    "\n",
    "# Setting Cutoffs\n",
    "fpr.shape\n",
    "\n",
    "df_cutoffs = pd.concat([pd.DataFrame(thresholds), pd.DataFrame(fpr), pd.DataFrame(tpr)], axis = 1)\n",
    "df_cutoffs.columns = ['thresholds', 'fpr', 'tpr']\n",
    "df_cutoffs.head()\n",
    "\n",
    "df_cutoffs['thresholds'][0] = 1 - 1 / np.power(10, 16)\n",
    "# Let the first threshold (the value of the thresholds column with index 0) be equal to a number, very close to 1\n",
    "# but smaller than 1, say 1 - 1 / 10 ^ 16.\n",
    "\n",
    "df_cutoffs.head()\n",
    "df_cutoffs.tail()\n",
    "df_accept.head()\n",
    "\n",
    "X_test.shape\n",
    "\n",
    "# We define a function called 'n_approved' which assigns a value of 1 if a predicted probability\n",
    "# is greater than the parameter p, which is a threshold, and a value of 0, if it is not.\n",
    "# Then it sums the column.\n",
    "# Thus, if given any percentage values, the function will return\n",
    "# the number of rows wih estimated probabilites less than the threshold. \n",
    "def n_approved(p):\n",
    "    return np.where(df_accept['Probability of default'] <= p, 1, 0).sum()\n",
    "\n",
    "df_cutoffs['N Approved'] = df_cutoffs['thresholds'].apply(n_approved)\n",
    "df_cutoffs['N Rejected'] = X_test.shape[0] - df_cutoffs['N Approved']\n",
    "df_cutoffs['Approval Rate'] = df_cutoffs['N Approved'] / df_accept['Probability of default'].shape[0]\n",
    "df_cutoffs['Rejection Rate'] = 1 - df_cutoffs['Approval Rate']\n",
    "\n",
    "df_cutoffs.iloc[40: , ]\n",
    "\n",
    "\n",
    "# Comparison of the different evalustion  metrices for each algorithm\n",
    "\n",
    "def bar_plot(ax, data, colors=None, total_width=0.8, single_width=1, legend=True):\n",
    "    \n",
    "    if colors is None:\n",
    "        colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "    # Number of bars per group\n",
    "    n_bars = len(data)\n",
    "\n",
    "    # The width of a single bar\n",
    "    bar_width = total_width / n_bars\n",
    "\n",
    "    # List containing handles for the drawn bars, used for the legend\n",
    "    bars = []\n",
    "\n",
    "    # Iterate over all data\n",
    "    for i, (name, values) in enumerate(data.items()):\n",
    "        # The offset in x direction of that bar\n",
    "        x_offset = (i - n_bars / 2) * bar_width + bar_width / 2\n",
    "\n",
    "        # Draw a bar for every value of that type\n",
    "        for x, y in enumerate(values):\n",
    "            bar = ax.bar(x + x_offset, y, width=bar_width * single_width, color=colors[i % len(colors)])\n",
    "\n",
    "        # Add a handle to the last drawn bar, which we'll need for the legend\n",
    "        bars.append(bar[0])\n",
    "\n",
    "    # Draw legend if we need\n",
    "    if legend:\n",
    "        ax.legend(bars, data.keys())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Usage example:\n",
    "    data = {\n",
    "        \"Accuracy\": [0.72, 0.69, 0.71, .69, .74, .70], \n",
    "        \"Error\" : [0.28, 0.31, 0.29, .31, .26, .30], \n",
    "        \"Recall\": [0.23, 0.7, 0.25, .17, .42, .43], \n",
    "        \"Specificity\": [0.95, 0.98, 0.93, .94, .90, .83],\n",
    "        \"Precision\": [0.88, 0.62, 0.69, .57, .32, .44],\n",
    "        \"F1-Score\": [.34, .13, 0.36, .26, .51, .48]\n",
    "}\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    bar_plot(ax, data, total_width=.8, single_width=.9)\n",
    "    \n",
    "    X = ['KNN','LR','NB', \"SVM\", \"RF\", \"CART\"]\n",
    "    X_axis = np.arange(len(X))\n",
    "    plt.xticks(X_axis, X)\n",
    "    \n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
